{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Programming\\Projects\\Public\\plant-lens\\ai\\ml\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "class_names = [ \"marigold\", \"jasmine\", \"rose\", \"hibiscus\", \"sunflower\", \"dahlia\", \"lotus\", \"bougainvillea\", \n",
    "\t\t\t\t\t\t\t\t\"chrysanthemum\", \"lily\", \"lavender\", \"aloe-vera\", \"snake-plant\", \"golden-barrel-cactus\"]\n",
    "class_count = len(class_names)\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files from dir to memory\n",
    "# Resize Image to [224, 224, 3]\n",
    "# Create a Train, Test, Validate Split\n",
    "train_dataset\n",
    "test_dataset\n",
    "validate_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " lambda_6 (Lambda)           (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " keras_layer_5 (KerasLayer)  (None, 1024)              1026552   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 14)                7182      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1558534 (5.95 MB)\n",
      "Trainable params: 531982 (2.03 MB)\n",
      "Non-trainable params: 1026552 (3.92 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Sequential, layers, applications\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "def build_model():\n",
    "    dimensions = 224\n",
    "    # Input layer\n",
    "    input_layer = layers.Input(shape=(dimensions, dimensions, 3))\n",
    "    # Preprocessing the input\n",
    "    preprocessing_layer = layers.Lambda(lambda x: applications.mobilenet_v3.preprocess_input(x))(input_layer)\n",
    "    feature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5', trainable=False)(preprocessing_layer)\n",
    "    hidden_layer = layers.Dense(512, activation='relu')(feature_extractor)\n",
    "    predictions = layers.Dense(class_count, activation='softmax')(hidden_layer)\n",
    "    model = Model(inputs=input_layer, outputs=predictions)\n",
    "    model.compile(optimizer ='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the model\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access metrics from training history\n",
    "print(\"\\ninitial accuracy: {} | latest accuracy: {}\".format(history.history[\"accuracy\"][0], history.history[\"accuracy\"][-1]))\n",
    "print(\"initial loss: {} | latest loss: {}\".format(history.history[\"loss\"][0], history.history[\"loss\"][-1]))\n",
    "\n",
    "fig, axis = plt.subplots(1, 2, figsize=(10,4)) \n",
    "# plot accuracy\n",
    "axis[0].plot(history.history[\"accuracy\"])\n",
    "axis[0].set_title(\"accuracy per epoch\")\n",
    "# plot loss\n",
    "axis[1].plot(history.history[\"loss\"])\n",
    "axis[1].set_title(\"loss per epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test loss:', test_loss, 'Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
